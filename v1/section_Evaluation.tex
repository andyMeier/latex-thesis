\section{Results}
The following section presents the results of the user study. We examined perceived understanding, self-reported trust and an implicit trust measure via the willingness to follow a classifier's recommendation. For each topic, we give the mean score, standard deviation, as well as a comparison of all conditions in a 9x9 matrix.\newline
The matrices show each condition checked for significant difference with every other condition. The colour scale is a visualisation of the differences in means ($\bar{x}_{row} - \bar{x}_{column}$ ), with negative differences coloured in red and positive differences in green. Per cell, the net difference values are displayed as well. The significance test results are added with asterisks, where one asterisk means significant at $\alpha=0.05$ significance level, while two asterisks denote significance at $\alpha=0.01$ significance level. The figures are available with a blue-red colour scheme in appendix B.\newline 

\paragraph{Demographics}
In total, 327 participants took part in the main user study with an average age of 29.4 years (SD = 8.8), a gender balance of 56\% (females) to 43\% (males) and two participants reporting the third gender. 87\% of the participants were recruited via ``Prolific", while 36 participants enlisted on ``SurveyCircle". 57\% self-assessed their level of English to be equivalent to a native speaker, 23\% as advanced (C1), 14\% as upper-intermediate (B2), and 5\% as lower than that. All participants claimed to be ``fluent" in English. The exclusion criteria (passed attention check and completion of whole questionnaire) invalidated 41 data points, resulting in 286 valid cases. More detailed statistics about the participants' backgrounds are given in appendix B.\newline

\paragraph{Perceived Understanding}
As figure \ref{fig:results_matrix_understanding} shows, users of the system with a very good classifier and no explanation report the highest perceived understanding. For the very good and the medium classifier, giving no explanations for the decisions leads to a higher perceived understanding than delivering placebic, i.e. random, explanations. In general, users have more confidence in their understanding of the system for the very good and medium classifiers as compared to the bad classifier. One condition, however, does not lead to significantly higher scores than the bad classifier: for the medium classifier with random explanations, users reported the same understanding as for the bad classifier with no explanations. Concerning the bad classifier, giving a truthful explanation for the decision leads to the lowest perceived understanding.

\begin{table}[h]
	\makebox[\textwidth][c]{
	\begin{tabular}{lrr|lrr|lrr}
		\textbf{Condition} & \textbf{Mean} & \textbf{SD} & \textbf{Condition} & \textbf{Mean} & \textbf{SD} & \textbf{Condition} & \textbf{Mean} & \textbf{SD} \\ \midrule
		super-good & 3.944 & 0.915 & super-rand & 3.729 & 0.860 & super-no & 4.147 & 0.701 \\
		medium-good & 3.818 & 0.825 & medium-rand & 2.944 & 0.963 & medium-no & 3.700 & 0.690 \\
		bad-good & 2.465 & 1.201 & bad-rand & 2.500 & 1.138 & bad-no & 2.944 & 1.152 \\ \bottomrule
	\end{tabular}}
	\caption{Mean scores for perceived understanding measure}
	\label{fig:results_table_understanding}
\end{table}

\begin{figure}[H]
	\makebox[\textwidth][c]{
		\begin{minipage}[t]{0.65\textwidth}
			\centering
			\includegraphics[width=\textwidth]{img/results_matrix_understanding.JPG}
			\caption{Comparison of perceived understanding scores ordered by classifier, value reporting difference of means ($\bar{x}_{row} - \bar{x}_{column}$ ), asterisk reporting significance (* significant at $\alpha=0.05$, ** significant at $\alpha=0.01$)}
			\label{fig:results_matrix_understanding}
		\end{minipage}%
		\hspace{5mm}
		\begin{minipage}[t]{0.65\textwidth}
			\centering
			\includegraphics[width=\textwidth]{img/results_matrix_understanding_reordered.JPG}
			\caption{Comparison of perceived understanding scores ordered by explanation type, value reporting difference of means ($\bar{x}_{row} - \bar{x}_{column}$ ), asterisk reporting significance (* significant at $\alpha=0.05$, ** significant at $\alpha=0.01$)}
			\label{fig:results_matrix_understanding_reordered}
		\end{minipage}}
\end{figure}


\paragraph{Trust Questionnaire}
The self-reported trust scores show similar results as the perceived understanding: Besides the medium classifier with random explanations, all systems lead to significantly more trust than the systems employing the bad classifier. The explanations do not play a role regarding user's trust when the bad classifier is used. Looking at the medium classifier, the random explanation leads to a lower trust score than no explanation and a good explanation, with no difference between the latter two. The most trust is evoked by the very good classifier without explanations, significantly more than for any other condition. There is no significant difference between the very good classifier with explanations and the medium classifier with meaningful explanation. For both the bad classifier and the very good classifier, the condition without any explanation again led to the highest scores within the same classifiers. The detailed results are presented in figure \ref{fig:results_matrix_trust}.

\begin{table}[h]
	\makebox[\textwidth][c]{
		\begin{tabular}{lrr|lrr|lrr}
			\textbf{Condition} & \textbf{Mean} & \textbf{SD} & \textbf{Condition} & \textbf{Mean} & \textbf{SD} & \textbf{Condition} & \textbf{Mean} & \textbf{SD} \\ \midrule
			super-good & 2.682 & 0.400 & super-rand & 2.679 & 0.482 & super-no & 2.995 & 0.512 \\
			medium-good & 2.633 & 0.482 & medium-rand & 2.211 & 0.509 & medium-no & 2.630 & 0.459 \\
			bad-good & 1.917 & 0.428 & bad-rand & 1.951 & 0.403 & bad-no & 2.018 & 0.546 \\ \bottomrule
	\end{tabular}}
	\caption{Mean scores for self-reported trust measure}
	\label{fig:results_table_trust}
\end{table}

\begin{figure}[H]
	\makebox[\textwidth][c]{
		\begin{minipage}[t]{0.65\textwidth}
			\centering
			\includegraphics[width=\textwidth]{img/results_matrix_trust.JPG}
			\caption{Comparison of trust scores ordered by classifier, value reporting difference of means ($\bar{x}_{row} - \bar{x}_{column}$ ), asterisk reporting significance (* significant at $\alpha=0.05$, ** significant at $\alpha=0.01$)}
			\label{fig:results_matrix_trust}
		\end{minipage}%
		\hspace{5mm}
		\begin{minipage}[t]{0.65\textwidth}
			\centering
			\includegraphics[width=\textwidth]{img/results_matrix_trust_reordered.JPG}
			\caption{Comparison of trust scores ordered by explanation type, value reporting difference of means ($\bar{x}_{row} - \bar{x}_{column}$ ), asterisk reporting significance (* significant at $\alpha=0.05$, ** significant at $\alpha=0.01$)}
			\label{fig:results_matrix_trust_reordered}
	\end{minipage}}
\end{figure}


\paragraph{Observed Trust via Proxy}
The second trust measure uses a proxy to determine the trust a user puts into a system: the willingness to follow a system's recommendation, in this case the decision about offensiveness and non-offensiveness. Figure \ref{fig:results_proxy_away} shows the results of analysing the user's willingness to change a classification to match the system's decision while contradicting the truth.\newline
The results presented in this section need to be analysed with caution. Consider the case of the very good classifier with meaningful explanations. Out of 30 cases in this condition, 16 did not have the possibility to show a change away from the truth towards the prediction of the classifier, because the classifier in those 16 cases did not make any mistakes. From the remaining 14 cases, 4 showed the behaviour in question, leading to a mean of 0.286. This result is higher than the other conditions' mean scores. The same issue appears in the data for changing from a faulty classification towards a correct classification in accordance with the bad classifier: Each participant in this condition had at most one possibility to show the behaviour in question. The sample sizes have to be reduced by the number of cases without possibility, leaving a size that is quite small for reliably detecting significant differences.\newline
The highest changing rate in favour of the system but against the true label was detected for users of the good classifier with a meaningful explanation, but also the highest variance. Users were significantly more likely to adapt the system's faulty decision when confronted with the good system with random and no explanations than the users of any system with the bad classifier. The same holds true for users of the medium classifier without explanations.\newline
\begin{table}[H]
	\makebox[\textwidth][c]{
		\begin{tabular}{lrrrrrrrr}
			\textbf{Condition} & 
			\head{1.5cm}{\textbf{Total cases}} & 
			\head{1.5cm}{\textbf{Cases with opportunities}} & 
			\head{1.5cm}{\textbf{Avg opportunities}} & 
			\head{1.5cm}{\textbf{Cases with changes}} & 
			\head{1.5cm}{\textbf{Avg changes}} & 
			\head{1.5cm}{\textbf{Cases with changes away}} & 
			\head{1.5cm}{\textbf{Avg changes away}} & 
			\head{1.5cm}{\textbf{Norma-lised mean}} \\ \midrule
			super-good &	30 &	 14 &	 0.47 &	 20 &	 1.40 &	 4 &	 0.29 &	 \textbf{0.29} \\
			super-rand &	32 &	 17 &	 0.53 &	 18 &	 1.09 &	 2 &	 0.12 &	 \textbf{0.12} \\
			super-no &	 	34 &	 23 &	 0.68 &	 18 &	 1.18 &	 1 &	 0.04 &	 \textbf{0.04} \\ 
			medium-good &	33 &	 33 &	 3.48 &	 17 &	 1.12 &	 7 &	 0.30 &	 \textbf{0.09} \\
			medium-rand &	30 &	 30 &	 3.57 &	 20 &	 1.37 &	 7 &	 0.30 &	 \textbf{0.08} \\
			medium-no &	30 &	 30 &	 3.40 &	 	20 &	 1.00 &	 5 &	 0.23 &	 \textbf{0.08} \\
			bad-good &	 	38 &	 38 &	 14.45 &	 20 &	 0.95 &	 17 &	 0.71 &	 \textbf{0.05} \\
			bad-rand &	 	30 &	 30 &	 14.27 &	 19 &	 1.13 &	 15 &	 0.77 &	 \textbf{0.05} \\
			bad-no &	 	30 &	 30 &	 14.27 &	 19 &	 1.23 &	 16 &	 1.03 &	 \textbf{0.07} \\ \bottomrule
	\end{tabular}}
	\caption{Statistics for trust measure via proxy (changes away from truth in favour of system decision)}
	\label{fig:results_table_proxy_away}
\end{table}

\begin{figure}[H]
	\makebox[\textwidth][c]{
		\begin{minipage}[t]{0.65\textwidth}
			\centering
			\includegraphics[width=\textwidth]{img/results_matrix_proxy_away.JPG}
			\caption{Comparison of proxy trust (away) scores ordered by classifier, value reporting difference of means ($\bar{x}_{row} - \bar{x}_{column}$ ), asterisk reporting significance (* significant at $\alpha=0.05$, ** significant at $\alpha=0.01$)}
			\label{fig:results_proxy_away}
		\end{minipage}%
		\hspace{5mm}
		\begin{minipage}[t]{0.65\textwidth}
			\centering
			\includegraphics[width=\textwidth]{img/results_matrix_proxy_away_reordered.JPG}
			\caption{Comparison of proxy trust (away) scores ordered by explanation type, value reporting difference of means ($\bar{x}_{row} - \bar{x}_{column}$ ), asterisk reporting significance (* significant at $\alpha=0.05$, ** significant at $\alpha=0.01$)}
			\label{fig:results_proxy_away_reordered}
	\end{minipage}}
\end{figure}
\noindent Tables \ref{tab:changes_super-good} to \ref{tab:changes_bad-no} show the changing behaviour of participants per condition, normalised over the amount of opportunities per cell. That is, if a classifier correctly classified 10 Tweets, and the participant correctly classified 9 of them as well, there are 9 opportunities to change \textit{away from the classifier} and \textit{away from the truth}, or, conversely, 1 opportunity to change \textit{towards the classifier} and \textit{towards the truth}. The absolute counts of changes can be found in appendix B.\newline
We interpret the behaviour of changing \textit{towards the classifier} but \textit{away from the truth} as being convinced by the system and willingness to accept a system's recommendation. Changes made \textit{away from the classifier} and \textit{towards the truth} is the ignorance or mistrust of the system, showing that the user is not following the system's recommendation. For the good classifier, the most relative changes indicating persuasion can be seen with \textit{super-good} and the least persuasion with \textit{super-no}. The same ordering is present in the changing behaviour with the medium classifier. For the bad classifier, the highest changing rate \textit{towards the classifier} and \textit{away from the truth} is seen with \textit{bad-no}, although the changing rates are lower than those measured with the good classifier.

\begin{figure}[H]
	\makebox[\textwidth][c]{
		\begin{minipage}[t]{0.65\textwidth}
			\centering
			\begin{table}[H]
				\centering
				\begin{tabular}{ll|rr}
					\multicolumn{2}{l|}{} & \multicolumn{2}{c}{\textbf{Truth}}\\
					\multicolumn{2}{l|}{} & Towards & Away \\ \midrule
					\multirow{2}{*}{\textbf{Classifier}} & Towards & 0.3048 & 0.3636 \\
					& Away & 0.0000 & 0.0181 \\ \midrule
					&  & 0.3048 & 0.3817 \\ \bottomrule
				\end{tabular}
				\caption{Change rates with super-good}
				\label{tab:changes_super-good}
			\end{table}
		\end{minipage}%
		\hspace{2mm}
		\begin{minipage}[t]{0.65\textwidth}
			\centering
			\begin{table}[H]
				\centering
				\begin{tabular}{ll|rr}
					\multicolumn{2}{l|}{} & \multicolumn{2}{c}{\textbf{Truth}}\\
					\multicolumn{2}{l|}{} & Towards & Away \\ \midrule
					\multirow{2}{*}{\textbf{Classifier}} & Towards & 0.2115 & 0.1667 \\
					& Away & 0.0000 & 0.0306 \\ \midrule
					&  & 0.2115 & 0.1973 \\ \bottomrule
				\end{tabular}
				\caption{Change rates with super-rand}
				\label{tab:changes_super-rand}
			\end{table}
	\end{minipage}}
\end{figure}
\vspace{-9mm}
\begin{figure}[H]
	\makebox[\textwidth][c]{
		\begin{minipage}[t]{0.65\textwidth}
			\centering
			\begin{table}[H]
				\centering
				\begin{tabular}{ll|rr}
					\multicolumn{2}{l|}{} & \multicolumn{2}{c}{\textbf{Truth}}\\
					\multicolumn{2}{l|}{} & Towards & Away \\ \midrule
					\multirow{2}{*}{\textbf{Classifier}} & Towards & 0.3163 & 0.0588 \\
					& Away & 0.0000 & 0.0206 \\ \midrule
					&  & 0.3163 & 0.0794 \\ \bottomrule
				\end{tabular}
				\caption{Change rates with super-no}
				\label{tab:changes_super-no}
			\end{table}
		\end{minipage}%
		\hspace{2mm}
		\begin{minipage}[t]{0.65\textwidth}
			\centering
			\begin{table}[H]
				\centering
				\begin{tabular}{ll|rr}
					\multicolumn{2}{l|}{} & \multicolumn{2}{c}{\textbf{Truth}}\\
					\multicolumn{2}{l|}{} & Towards & Away \\ \midrule
					\multirow{2}{*}{\textbf{Classifier}} & Towards & 0.3143 & 0.1163 \\
					& Away & 0.1034 & 0.0065 \\ \midrule
					&  & 0.4177 & 0.1228 \\ \bottomrule
				\end{tabular}
				\caption{Change rates with medium-good}
				\label{tab:changes_medium-good}
			\end{table}
	\end{minipage}}
\end{figure}
\vspace{-9mm}
\begin{figure}[H]
	\makebox[\textwidth][c]{
		\begin{minipage}[t]{0.65\textwidth}
			\centering
			\begin{table}[H]
				\centering
				\begin{tabular}{ll|rr}
					\multicolumn{2}{l|}{} & \multicolumn{2}{c}{\textbf{Truth}}\\
					\multicolumn{2}{l|}{} & Towards & Away \\ \midrule
					\multirow{2}{*}{\textbf{Classifier}} & Towards & 0.2125 & 0.1071 \\
					& Away & 0.1304 & 0.0456 \\ \midrule
					&  & 0.3429 & 0.1527 \\ \bottomrule
				\end{tabular}
				\caption{Change rates with medium-rand}
				\label{tab:changes_medium-rand}
			\end{table}
		\end{minipage}%
		\hspace{2mm}
		\begin{minipage}[t]{0.65\textwidth}
			\centering
			\begin{table}[H]
				\centering
				\begin{tabular}{ll|rr}
					\multicolumn{2}{l|}{} & \multicolumn{2}{c}{\textbf{Truth}}\\
					\multicolumn{2}{l|}{} & Towards & Away \\ \midrule
					\multirow{2}{*}{\textbf{Classifier}} & Towards & 0.2985 & 0.0921 \\
					& Away & 0.0385 & 0.0071 \\ \midrule
					&  & 0.3370 & 0.0992 \\ \bottomrule
				\end{tabular}
				\caption{Change rates with medium-no}
				\label{tab:changes_medium-no}
			\end{table}
	\end{minipage}}
\end{figure}
\vspace{-9mm}
\begin{figure}[H]
	\makebox[\textwidth][c]{
		\begin{minipage}[t]{0.65\textwidth}
			\centering
			\begin{table}[H]
				\centering
				\begin{tabular}{ll|rr}
					\multicolumn{2}{l|}{} & \multicolumn{2}{c}{\textbf{Truth}}\\
					\multicolumn{2}{l|}{} & Towards & Away \\ \midrule
					\multirow{2}{*}{\textbf{Classifier}} & Towards & 0.1667 & 0.0607 \\
					& Away & 0.0673 & 0.0667 \\ \midrule
					&  & 0.2340 & 0.1274 \\ \bottomrule
				\end{tabular}
				\caption{Change rates with bad-good}
				\label{tab:changes_bad-good}
			\end{table}
		\end{minipage}%
		\hspace{2mm}
		\begin{minipage}[t]{0.65\textwidth}
			\centering
			\begin{table}[H]
				\centering
				\begin{tabular}{ll|rr}
					\multicolumn{2}{l|}{} & \multicolumn{2}{c}{\textbf{Truth}}\\
					\multicolumn{2}{l|}{} & Towards & Away \\ \midrule
					\multirow{2}{*}{\textbf{Classifier}} & Towards & 0.2500 & 0.0689 \\
					& Away & 0.1064 & 0.0000 \\ \midrule
					&  & 0.3564 & 0.0689 \\ \bottomrule
				\end{tabular}
				\caption{Change rates with bad-rand}
				\label{tab:changes_bad-rand}
			\end{table}
	\end{minipage}}
\end{figure}
\vspace{-5mm}
\begin{table}[H]
	\centering
	\begin{tabular}{ll|rr}
		\multicolumn{2}{l|}{} & \multicolumn{2}{c}{\textbf{Truth}}\\
		\multicolumn{2}{l|}{} & Towards & Away \\ \midrule
		\multirow{2}{*}{\textbf{Classifier}} & Towards & 0.3333 & 0.0920 \\
		& Away & 0.0440 & 0.0000 \\ \midrule
		&  & 0.3773 & 0.0920 \\ \bottomrule
	\end{tabular}
	\caption{Change rates with bad-no}
	\label{tab:changes_bad-no}
\end{table}




\paragraph{Predictability}
The questionnaire used to measure self-perceived trust categorises six factors of trust. Although this research does not aim to investigate trust in more detail, we look at predictability in isolation, since we have two classifiers at the extremes which are predictable in their behaviour. Figure \ref{fig:results_matrix_predictability} and \ref{fig:results_matrix_predictability_reordered} show the results of comparing the predictability scores. The highest predictability was reported for \textit{super-no}, and the lowest for \textit{bad-rand}. All systems using the very good classifier are perceived to be significantly more predictable than the systems based on the bad classifier.
\begin{table}[h]
	\makebox[\textwidth][c]{
		\begin{tabular}{lrr|lrr|lrr}
			\textbf{Condition} & \textbf{Mean} & \textbf{SD} & \textbf{Condition} & \textbf{Mean} & \textbf{SD} & \textbf{Condition} & \textbf{Mean} & \textbf{SD} \\ \midrule
			super-good & 3.033 & 0.755 & super-rand & 2.914 & 0.814 & super-no & 3.213 & 0.725 \\
			medium-good & 2.864 & 0.594 & medium-rand & 2.308 & 0.833 & medium-no & 2.675 & 0.756 \\
			bad-good & 2.013 & 0.644 & bad-rand & 1.850 & 0.679 & bad-no & 2.117 & 0.763 \\ \bottomrule
	\end{tabular}}
	\caption{Mean scores for predictability}
	\label{fig:results_table_predictability}
\end{table}

\begin{figure}[H]
	\makebox[\textwidth][c]{
		\begin{minipage}[t]{0.65\textwidth}
			\centering
			\includegraphics[width=\textwidth]{img/results_matrix_predictability.JPG}
			\caption{Comparison of predictability scores ordered by classifier, value reporting difference of means ($\bar{x}_{row} - \bar{x}_{column}$ ), asterisk reporting significance (* significant at $\alpha=0.05$, ** significant at $\alpha=0.01$)}
			\label{fig:results_matrix_predictability}
		\end{minipage}%
		\hspace{5mm}
		\begin{minipage}[t]{0.65\textwidth}
			\centering
			\includegraphics[width=\textwidth]{img/results_matrix_predictability_reordered.JPG}
			\caption{Comparison of predictability scores ordered by explanation type, value reporting difference of means ($\bar{x}_{row} - \bar{x}_{column}$ ), asterisk reporting significance (* significant at $\alpha=0.05$, ** significant at $\alpha=0.01$)}
			\label{fig:results_matrix_predictability_reordered}
	\end{minipage}}
\end{figure}





\begin{thebibliography}{10}

\bibitem{allahyari2011user}
H.~Alahyari and N.~Lavesson.
\newblock User-oriented assessment of classification model understandability.
\newblock In {\em Frontiers in Artificial Intelligence and Applications},
  volume 227, pages 11--19. SCAI, 05 2011.

\bibitem{arras2017relevant}
L.~Arras, F.~Horn, G.~Montavon, K.-R. M{\"u}ller, and W.~Samek.
\newblock ``what is relevant in a text document?": An interpretable machine
  learning approach.
\newblock {\em PloS one}, 12(8):e0181142, 2017.

\bibitem{artz2007survey}
D.~Artz and Y.~Gil.
\newblock A survey of trust in computer science and the semantic web.
\newblock {\em Web Semantics: Science, Services and Agents on the World Wide
  Web}, 5(2):58--71, 2007.

\bibitem{baldoni2016computational}
M.~Baldoni, C.~Baroglio, K.~M. May, R.~Micalizio, and S.~Tedeschi.
\newblock Computational accountability.
\newblock In {\em CEUR Workshop Proceedings}, volume 1802, pages 56--62, 2016.

\bibitem{ball2015development}
L.~E. Ball and M.~D. Leveritt.
\newblock Development of a validated questionnaire to measure the
  self-perceived competence of primary health professionals in providing
  nutrition care to patients with chronic disease.
\newblock {\em Family practice}, 32(6):706--710, 2015.

\bibitem{becker2006trustworthy}
S.~Becker, W.~Hasselbring, A.~Paul, M.~Boskovic, H.~Koziolek, J.~Ploski,
  A.~Dhama, H.~Lipskoch, M.~Rohr, D.~Winteler, et~al.
\newblock Trustworthy software systems: a discussion of basic concepts and
  terminology.
\newblock {\em ACM SIGSOFT Software Engineering Notes}, 31(6):1--18, 2006.

\bibitem{bedi2006assessing}
P.~Bedi and H.~Banati.
\newblock Assessing user trust to improve web usability.
\newblock {\em Journal of computer Science}, 2(3):283--7, 2006.

\bibitem{bibal2016interpretability}
A.~Bibal and B.~Fr{\'e}nay.
\newblock Interpretability of machine learning models and representations: an
  introduction.
\newblock In {\em Proceedings on ESANN}, pages 77--82, 2016.

\bibitem{biran2017explanation}
O.~Biran and C.~Cotton.
\newblock Explanation and justification in machine learning: A survey.
\newblock In {\em IJCAI-17 Workshop on Explainable AI (XAI)}, page~8, 2017.

\bibitem{blumer1987occam}
A.~Blumer, A.~Ehrenfeucht, D.~Haussler, and M.~K. Warmuth.
\newblock Occam's razor.
\newblock {\em Information processing letters}, 24(6):377--380, 1987.

\bibitem{broadbent2006brief}
E.~Broadbent, K.~J. Petrie, J.~Main, and J.~Weinman.
\newblock The brief illness perception questionnaire.
\newblock {\em Journal of psychosomatic research}, 60(6):631--637, 2006.

\bibitem{burrell2016machine}
J.~Burrell.
\newblock How the machine 'thinks': Understanding opacity in machine learning
  algorithms.
\newblock {\em Big Data \& Society}, 3(1):2053951715622512, 2016.

\bibitem{chen2018learning}
J.~Chen, L.~Song, M.~J. Wainwright, and M.~I. Jordan.
\newblock Learning to explain: An information-theoretic perspective on model
  interpretation.
\newblock In {\em Proceedings of the 35th International Conference on Machine
  Learning}, volume~80, pages 883--892. PMLR, 10--15 Jul 2018.

\bibitem{chen2012detecting}
Y.~Chen, Y.~Zhou, S.~Zhu, and H.~Xu.
\newblock Detecting offensive language in social media to protect adolescent
  online safety.
\newblock In {\em Privacy, Security, Risk and Trust (PASSAT), 2012
  International Conference on and 2012 International Confernece on Social
  Computing (SocialCom)}, pages 71--80. IEEE, 2012.

\bibitem{cheung1997mann}
Y.~K. Cheung and J.~H. Klotz.
\newblock The mann whitney wilcoxon distribution using linked lists.
\newblock {\em Statistica Sinica}, pages 805--813, 1997.

\bibitem{corritore2005measuring}
C.~L. Corritore, R.~P. Marble, S.~Wiedenbeck, B.~Kracher, and A.~Chandran.
\newblock Measuring online trust of websites: Credibility, perceived ease of
  use, and risk.
\newblock {\em AMCIS 2005 Proceedings}, page 370, 2005.

\bibitem{cramer2008effects}
H.~Cramer, V.~Evers, S.~Ramlal, M.~Van~Someren, L.~Rutledge, N.~Stash,
  L.~Aroyo, and B.~Wielinga.
\newblock The effects of transparency on trust in and acceptance of a
  content-based art recommender.
\newblock {\em User Modeling and User-Adapted Interaction}, 18(5):455, 2008.

\bibitem{datta2015automated}
A.~Datta, M.~C. Tschantz, and A.~Datta.
\newblock Automated experiments on ad privacy settings.
\newblock {\em Proceedings on Privacy Enhancing Technologies}, 2015(1):92--112,
  2015.

\bibitem{davidson2017automated}
T.~Davidson, D.~Warmsley, M.~Macy, and I.~Weber.
\newblock Automated hate speech detection and the problem of offensive
  language.
\newblock In {\em Proceedings of the 11th International AAAI Conference on Web
  and Social Media}, ICWSM '17, pages 512--515, 2017.

\bibitem{del2017hate}
F.~Del~Vigna, A.~Cimino, F.~Dellâ€™Orletta, M.~Petrocchi, and M.~Tesconi.
\newblock Hate me, hate me not: Hate speech detection on facebook.
\newblock In {\em Proceedings of the 1st Italian Conference on Cybersecurity},
  ITASEC17, 2017.

\bibitem{diakopoulos2016accountability}
N.~Diakopoulos.
\newblock Accountability in algorithmic decision making.
\newblock {\em Communications of the ACM}, 59(2):56--62, 2016.

\bibitem{domingos2012few}
P.~Domingos.
\newblock A few useful things to know about machine learning.
\newblock {\em Communications of the ACM}, 55(10):78--87, 2012.

\bibitem{feng2018pathologies}
S.~Feng, E.~Wallace, A.~Grissom~II, M.~Iyyer, P.~Rodriguez, and J.~Boyd-Graber.
\newblock Pathologies of neural models make interpretations difficult.
\newblock In {\em Proceedings of the 2018 Conference on Empirical Methods in
  Natural Language Processing}, pages 3719--3728, 2018.

\bibitem{ghorai2016information}
T.~Ghorai.
\newblock An information retrieval system for fire 2016 microblog track.
\newblock In {\em Workshop Proceedings working notes of Forum for Information
  Retrieval Evaluation (FIRE)}, volume 1737 of {\em CEUR '16}, pages 81--83.
  CEUR-WS.org, 2016.

\bibitem{gilpin2018explaining}
L.~H. Gilpin, D.~Bau, B.~Z. Yuan, A.~Bajwa, M.~Specter, and L.~Kagal.
\newblock Explaining explanations: An approach to evaluating interpretability
  of machine learning.
\newblock {\em arXiv preprint arXiv:1806.00069}, 2018.

\bibitem{glass2008toward}
A.~Glass, D.~L. McGuinness, and M.~Wolverton.
\newblock Toward establishing trust in adaptive agents.
\newblock In {\em Proceedings of the 13th international conference on
  Intelligent user interfaces}, pages 227--236. ACM, 2008.

\bibitem{goodman16eu}
B.~Goodman and S.~Flaxman.
\newblock Eu regulations on algorithmic decision-making and a "right to
  explanation".
\newblock {\em AI Magazine}, 38, 06 2016.

\bibitem{guidotti2018survey}
R.~Guidotti, A.~Monreale, S.~Ruggieri, F.~Turini, F.~Giannotti, and
  D.~Pedreschi.
\newblock A survey of methods for explaining black box models.
\newblock {\em ACM Computing Surveys (CSUR)}, 51(5):93, 2018.

\bibitem{gupta2018proposed}
P.~Gupta, A.~Kamra, R.~Thakral, M.~Aggarwal, S.~Bhatti, and V.~Jain.
\newblock A proposed framework to analyze abusive tweets on the social
  networks.
\newblock {\em International Journal of Modern Education and Computer Science},
  10(1):46, 2018.

\bibitem{hemalatha2012preprocessing}
I.~Hemalatha, G.~S. Varma, and A.~Govardhan.
\newblock Preprocessing the informal text for efficient sentiment analysis.
\newblock {\em International Journal of Emerging Trends \& Technology in
  Computer Science (IJETTCS)}, 1(2):58--61, 2012.

\bibitem{hendricks2018generating}
L.~A. Hendricks, R.~Hu, T.~Darrell, and Z.~Akata.
\newblock Generating counterfactual explanations with natural language.
\newblock In {\em ICML Workshop on Human Interpretability in Machine Learning},
  2018.

\bibitem{herman2017promise}
B.~Herman.
\newblock The promise and peril of human evaluation for model interpretability.
\newblock In {\em NIPS 2017 Symposium on Interpretable Machine Learning}, 2017.

\bibitem{hovelmann2017fasttext}
L.~H{\"o}velmann and C.~M. Friedrich.
\newblock Fasttext and gradient boosted trees at germeval-2017 on relevance
  classification and document-level polarity.
\newblock {\em Shared Task on Aspect-based Sentiment in Social Media Customer
  Feedback}, page~30, 2017.

\bibitem{hu2012text}
X.~Hu and H.~Liu.
\newblock Text analytics in social media.
\newblock In {\em Mining text data}, pages 385--414. Springer, 2012.

\bibitem{jay2008pragmatics}
T.~Jay and K.~Janschewitz.
\newblock The pragmatics of swearing.
\newblock {\em Journal of Politeness Research. Language, Behaviour, Culture},
  4(2):267--288, 2008.

\bibitem{joffe2001quality}
S.~Joffe, E.~F. Cook, P.~D. Cleary, J.~W. Clark, and J.~C. Weeks.
\newblock Quality of informed consent: a new measure of understanding among
  research subjects.
\newblock {\em Journal of the National Cancer Institute}, 93(2):139--147, 2001.

\bibitem{keil2006explanation}
F.~C. Keil.
\newblock Explanation and understanding.
\newblock {\em Annu. Rev. Psychol.}, 57:227--254, 2006.

\bibitem{klenner2018offensive}
M.~Klenner.
\newblock Offensive language without offensive words (olwow).
\newblock {\em Austrian Academy of Sciences, Vienna September 21, 2018}, 2018.

\bibitem{korber2018theoretical}
M.~K{\"o}rber.
\newblock Theoretical considerations and development of a questionnaire to
  measure trust in automation.
\newblock In {\em Congress of the International Ergonomics Association}, pages
  13--30. Springer, 2018.

\bibitem{kotsiantis2007supervised}
S.~B. Kotsiantis, I.~Zaharakis, and P.~Pintelas.
\newblock Supervised machine learning: A review of classification techniques.
\newblock {\em Emerging artificial intelligence applications in computer
  engineering}, 160:3--24, 2007.

\bibitem{kulesza2013too}
T.~Kulesza, S.~Stumpf, M.~Burnett, S.~Yang, I.~Kwan, and W.-K. Wong.
\newblock Too much, too little, or just right? ways explanations impact end
  users' mental models.
\newblock In {\em Visual Languages and Human-Centric Computing (VL/HCC), 2013
  IEEE Symposium on}, pages 3--10. IEEE, 2013.

\bibitem{langer1978mindlessness}
E.~J. Langer, A.~Blank, and B.~Chanowitz.
\newblock The mindlessness of ostensibly thoughtful action: The role of
  ``placebic" information in interpersonal interaction.
\newblock {\em Journal of personality and social psychology}, 36(6):635, 1978.

\bibitem{lipton2016mythos}
Z.~Lipton.
\newblock The mythos of model interpretability.
\newblock In {\em ICML Workshop on Human Interpretability in Machine Learning
  (WHI 2016)}. ICML, 2016.

\bibitem{liu2017towards}
S.~Liu, X.~Wang, M.~Liu, and J.~Zhu.
\newblock Towards better analysis of machine learning models: A visual
  analytics perspective.
\newblock {\em Visual Informatics}, 1(1):48--56, 2017.

\bibitem{mayer1995integrative}
R.~C. Mayer, J.~H. Davis, and F.~D. Schoorman.
\newblock An integrative model of organizational trust.
\newblock {\em Academy of management review}, 20(3):709--734, 1995.

\bibitem{melville2009sentiment}
P.~Melville, W.~Gryc, and R.~D. Lawrence.
\newblock Sentiment analysis of blogs by combining lexical knowledge with text
  classification.
\newblock In {\em Proceedings of the 15th ACM SIGKDD international conference
  on Knowledge discovery and data mining}, pages 1275--1284. ACM, 2009.

\bibitem{miller2017explanation}
T.~Miller.
\newblock Explanation in artificial intelligence: insights from the social
  sciences.
\newblock {\em arXiv preprint arXiv:1706.07269}, 2017.

\bibitem{mohammadi2013trustworthiness}
N.~G. Mohammadi, S.~Paulus, M.~Bishr, A.~Metzger, H.~K{\"o}nnecke,
  S.~Hartenstein, T.~Weyer, and K.~Pohl.
\newblock Trustworthiness attributes and metrics for engineering trusted
  internet-based software systems.
\newblock In {\em International Conference on Cloud Computing and Services
  Science}, pages 19--35. Springer, 2013.

\bibitem{montani2018tuwienkbs}
J.~P. Montani.
\newblock Tuwienkbs at germeval 2018: German abusive tweet detection.
\newblock {\em Austrian Academy of Sciences, Vienna September 21, 2018}, 2018.

\bibitem{council2001common}
C.~of~Europe. Council for Cultural Co-operation. Education Committee. Modern
  Languages~Division.
\newblock {\em Common European Framework of Reference for Languages: learning,
  teaching, assessment}.
\newblock Cambridge University Press, 2001.

\bibitem{poursabzi2017manipulating}
F.~Poursabzi-Sangdeh, D.~G. Goldstein, J.~M. Hofman, J.~W. Vaughan, and
  H.~Wallach.
\newblock Manipulating and measuring model interpretability.
\newblock In {\em NIPS 2017 Symposium on Interpretable Machine Learning}, 2017.

\bibitem{preece2018asking}
A.~Preece.
\newblock Asking 'why' in ai: Explainability of intelligent
  systems--perspectives and challenges.
\newblock {\em Intelligent Systems in Accounting, Finance and Management},
  25(2):63--72, 2018.

\bibitem{racine2018participants}
E.~Racine, C.~Hurley, A.~Cheung, C.~Sinnott, K.~Matvienko-Sikar,
  C.~Baumgartner, N.~Rodondi, W.~H. Smithson, and P.~M. Kearney.
\newblock Participantsâ€™ perspectives and preferences on clinical trial result
  dissemination: The trust thyroid trial experience.
\newblock {\em HRB Open Research}, 1, 2018.

\bibitem{rempel1985trust}
J.~K. Rempel, J.~G. Holmes, and M.~P. Zanna.
\newblock Trust in close relationships.
\newblock {\em Journal of personality and social psychology}, 49(1):95, 1985.

\bibitem{ribeiro2016should}
M.~T. Ribeiro, S.~Singh, and C.~Guestrin.
\newblock Why should i trust you?: Explaining the predictions of any
  classifier.
\newblock In {\em Proceedings of the 22nd ACM SIGKDD international conference
  on knowledge discovery and data mining}, pages 1135--1144. ACM, 2016.

\bibitem{ribeiro2018anchors}
M.~T. Ribeiro, S.~Singh, and C.~Guestrin.
\newblock Anchors: High-precision model-agnostic explanations.
\newblock In {\em AAAI Conference on Artificial Intelligence}, 2018.

\bibitem{richardson2018survey}
A.~Richardson and A.~Rosenfeld.
\newblock A survey of interpretability and explainability in human-agent
  systems.
\newblock In {\em XAI Workshop on Explainable Artificial Intelligence}, pages
  137--143, 2018.

\bibitem{rother2018ulmfit}
K.~Rother, M.~Allee, and A.~Rettberg.
\newblock Ulmfit at germeval-2018: A deep neural language model for the
  classification of hate speech in german tweets.
\newblock {\em Austrian Academy of Sciences, Vienna September 21, 2018}, 2018.

\bibitem{ruping2006learning}
S.~R{\"u}ping.
\newblock {\em Learning interpretable models}.
\newblock Doctoral thesis, Technical University Dortmund, 2006.

\bibitem{selbst2017meaningful}
A.~D. Selbst and J.~Powles.
\newblock Meaningful information and the right to explanation.
\newblock {\em International Data Privacy Law}, 7(4):233--242, 2017.

\bibitem{shepperd2014researcher}
M.~Shepperd, D.~Bowes, and T.~Hall.
\newblock Researcher bias: The use of machine learning in software defect
  prediction.
\newblock {\em IEEE Transactions on Software Engineering}, 40(6):603--616,
  2014.

\bibitem{skeem2016risk}
J.~Skeem and C.~Lowenkamp.
\newblock Risk, race, and recidivism: Predictive bias and disparate impact.
\newblock {\em Criminology}, 54, 11 2016.

\bibitem{smailovic2013predictive}
J.~Smailovi{\'c}, M.~Gr{\v{c}}ar, N.~Lavra{\v{c}}, and
  M.~{\v{Z}}nidar{\v{s}}i{\v{c}}.
\newblock Predictive sentiment analysis of tweets: A stock market application.
\newblock In {\em Human-computer interaction and knowledge discovery in
  complex, unstructured, Big Data}, pages 77--88. Springer, 2013.

\bibitem{van2018contrastive}
J.~van~der Waa, J.~van Diggelen, K.~van~den Bosch, and M.~Neerincx.
\newblock Contrastive explanations for reinforcement learning in terms of
  expected consequences.
\newblock {\em XAI 2018}, page 165, 2018.

\bibitem{van2001perceived}
C.~L. Van~Ess.
\newblock Perceived knowledge of heart failure and adherence to self-care
  recommendations.
\newblock Master thesis, Grand Valley State University, 2001.

\bibitem{ventocilla2018taxonomy}
E.~Ventocilla, T.~Helldin, M.~Riveiro, J.~Bae, V.~Boeva, G.~Falkmann, and
  N.~Lavesson.
\newblock Towards a taxonomy for interpretable and interactive machine
  learning.
\newblock In {\em XAI Workshop on Explainable Artificial Intelligence}, pages
  151--157, 2018.

\bibitem{vorm2018assessing}
E.~S. Vorm.
\newblock Assessing demand for transparency in intelligent systems using
  machine learning.
\newblock In {\em 2018 Innovations in Intelligent Systems and Applications
  (INISTA)}, pages 1--7. IEEE, 2018.

\bibitem{wachter2017right}
S.~Wachter, B.~Mittelstadt, and L.~Floridi.
\newblock Why a right to explanation of automated decision-making does not
  exist in the general data protection regulation.
\newblock {\em International Data Privacy Law}, 7(2):76--99, 2017.

\bibitem{watanabe2018hate}
H.~Watanabe, M.~Bouazizi, and T.~Ohtsuki.
\newblock Hate speech on twitter: A pragmatic approach to collect hateful and
  offensive expressions and perform hate speech detection.
\newblock {\em IEEE Access}, 6:13825--13835, 2018.

\bibitem{weihs2003combining}
C.~Weihs and U.~Sondhauss.
\newblock Combining mental fit and data fit for classification rule selection.
\newblock In {\em Exploratory Data Analysis in Empirical Research}, pages
  188--203. Springer, 2003.

\bibitem{weller2017challenges}
A.~Weller.
\newblock Challenges for transparency.
\newblock In {\em ICML Workshop on Human Interpretability in Machine Learning
  (WHI 2017)}. ICML, 2017.

\bibitem{xiang2012detecting}
G.~Xiang, B.~Fan, L.~Wang, J.~Hong, and C.~Rose.
\newblock Detecting offensive tweets via topical feature discovery over a large
  scale twitter corpus.
\newblock In {\em Proceedings of the 21st ACM international conference on
  Information and knowledge management}, pages 1980--1984. ACM, 2012.

\bibitem{zamalia2016students}
M.~Zamalia and A.~L. Porter.
\newblock Students' perceived understanding and competency in probability
  concepts in an e-learning environment: An australian experience.
\newblock {\em Pertanika Journal of Social Science and Humanities}, 24:73--82,
  2016.

\bibitem{vzliobaite2017measuring}
I.~{\v{Z}}liobait{\.e}.
\newblock Measuring discrimination in algorithmic decision making.
\newblock {\em Data Mining and Knowledge Discovery}, 31(4):1060--1089, 2017.

\end{thebibliography}

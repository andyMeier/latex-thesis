\begin{thebibliography}{10}

\bibitem{allahyari2011user}
Hiva Allahyari and Niklas Lavesson.
\newblock User-oriented assessment of classification model understandability.
\newblock In {\em 11th scandinavian conference on Artificial intelligence}. IOS
  Press, 2011.

\bibitem{baldoni2016computational}
Matteo Baldoni, Cristina Baroglio, Katherine~M May, Roberto Micalizio, and
  Stefano Tedeschi.
\newblock Computational accountability.
\newblock In {\em CEUR Workshop Proceedings}, volume 1802, pages 56--62. CEUR
  Workshop Proceedings, 2016.

\bibitem{bibal2016interpretability}
Adrien Bibal and Beno{\^\i}t Fr{\'e}nay.
\newblock Interpretability of machine learning models and representations: an
  introduction.
\newblock In {\em Proceedings on ESANN}, pages 77--82, 2016.

\bibitem{biran2017explanation}
Or~Biran and Courtenay Cotton.
\newblock Explanation and justification in machine learning: A survey.
\newblock In {\em IJCAI-17 Workshop on Explainable AI (XAI)}, page~8, 2017.

\bibitem{burrell2016machine}
Jenna Burrell.
\newblock How the machine ‘thinks’: Understanding opacity in machine
  learning algorithms.
\newblock {\em Big Data \& Society}, 3(1):2053951715622512, 2016.

\bibitem{chen2018learning}
Jianbo Chen, Le~Song, Martin~J Wainwright, and Michael~I Jordan.
\newblock Learning to explain: An information-theoretic perspective on model
  interpretation.
\newblock 80:883--892, 10--15 Jul 2018.

\bibitem{cramer2008effects}
Henriette Cramer, Vanessa Evers, Satyan Ramlal, Maarten Van~Someren, Lloyd
  Rutledge, Natalia Stash, Lora Aroyo, and Bob Wielinga.
\newblock The effects of transparency on trust in and acceptance of a
  content-based art recommender.
\newblock {\em User Modeling and User-Adapted Interaction}, 18(5):455, 2008.

\bibitem{davidson2017automated}
Thomas Davidson, Dana Warmsley, Michael Macy, and Ingmar Weber.
\newblock Automated hate speech detection and the problem of offensive
  language.
\newblock In {\em Proceedings of the 11th International AAAI Conference on Web
  and Social Media}, ICWSM '17, pages 512--515, 2017.

\bibitem{diakopoulos2016accountability}
Nicholas Diakopoulos.
\newblock Accountability in algorithmic decision making.
\newblock {\em Communications of the ACM}, 59(2):56--62, 2016.

\bibitem{domingos2012few}
Pedro Domingos.
\newblock A few useful things to know about machine learning.
\newblock {\em Communications of the ACM}, 55(10):78--87, 2012.

\bibitem{ghorai2016information}
T.~Ghorai.
\newblock An information retrieval system for fire 2016 microblog track.
\newblock In {\em Workshop Proceedings working notes of Forum for Information
  Retrieval Evaluation (FIRE)}, volume 1737 of {\em CEUR '16}, pages 81--83.
  CEUR-WS.org, 2016.

\bibitem{gilpin2018explaining}
Leilani~H Gilpin, David Bau, Ben~Z Yuan, Ayesha Bajwa, Michael Specter, and
  Lalana Kagal.
\newblock Explaining explanations: An approach to evaluating interpretability
  of machine learning.
\newblock {\em arXiv preprint arXiv:1806.00069}, 2018.

\bibitem{goodman16eu}
Bryce Goodman and Seth Flaxman.
\newblock Eu regulations on algorithmic decision-making and a "right to
  explanation".
\newblock {\em AI Magazine}, 38, 06 2016.

\bibitem{guidotti2018survey}
Riccardo Guidotti, Anna Monreale, Salvatore Ruggieri, Franco Turini, Fosca
  Giannotti, and Dino Pedreschi.
\newblock A survey of methods for explaining black box models.
\newblock {\em ACM Computing Surveys (CSUR)}, 51(5):93, 2018.

\bibitem{gupta2018proposed}
Priya Gupta, Aditi Kamra, Richa Thakral, Mayank Aggarwal, Sohail Bhatti, and
  Vishal Jain.
\newblock A proposed framework to analyze abusive tweets on the social
  networks.
\newblock {\em International Journal of Modern Education and Computer Science},
  10(1):46, 2018.

\bibitem{hemalatha2012preprocessing}
I~Hemalatha, GP~Saradhi Varma, and A~Govardhan.
\newblock Preprocessing the informal text for efficient sentiment analysis.
\newblock {\em International Journal of Emerging Trends \& Technology in
  Computer Science (IJETTCS)}, 1(2):58--61, 2012.

\bibitem{hendricks2018generating}
Lisa~Anne Hendricks, Ronghang Hu, Trevor Darrell, and Zeynep Akata.
\newblock Generating counterfactual explanations with natural language.
\newblock In {\em ICML Workshop on Human Interpretability in Machine Learning},
  2018.

\bibitem{herman2017promise}
B~Herman.
\newblock The promise and peril of human evaluation for model interpretability.
\newblock In {\em NIPS 2017 Symposium on Interpretable Machine Learning}, 2017.

\bibitem{hovelmann2017fasttext}
Leonard H{\"o}velmann and Christoph~M Friedrich.
\newblock Fasttext and gradient boosted trees at germeval-2017 on relevance
  classification and document-level polarity.
\newblock {\em Shared Task on Aspect-based Sentiment in Social Media Customer
  Feedback}, page~30, 2017.

\bibitem{hu2012text}
Xia Hu and Huan Liu.
\newblock Text analytics in social media.
\newblock In {\em Mining text data}, pages 385--414. Springer, 2012.

\bibitem{kotsiantis2007supervised}
Sotiris~B Kotsiantis, I~Zaharakis, and P~Pintelas.
\newblock Supervised machine learning: A review of classification techniques.
\newblock {\em Emerging artificial intelligence applications in computer
  engineering}, 160:3--24, 2007.

\bibitem{kulesza2013too}
Todd Kulesza, Simone Stumpf, Margaret Burnett, Sherry Yang, Irwin Kwan, and
  Weng-Keen Wong.
\newblock Too much, too little, or just right? ways explanations impact end
  users' mental models.
\newblock In {\em Visual Languages and Human-Centric Computing (VL/HCC), 2013
  IEEE Symposium on}, pages 3--10. IEEE, 2013.

\bibitem{lipton2016mythos}
Zachary Lipton.
\newblock The mythos of model interpretability.
\newblock In {\em ICML Workshop on Human Interpretability in Machine Learning
  (WHI 2016)}. ICML, 2016.

\bibitem{liu2017towards}
Shixia Liu, Xiting Wang, Mengchen Liu, and Jun Zhu.
\newblock Towards better analysis of machine learning models: A visual
  analytics perspective.
\newblock {\em Visual Informatics}, 1(1):48--56, 2017.

\bibitem{melville2009sentiment}
Prem Melville, Wojciech Gryc, and Richard~D Lawrence.
\newblock Sentiment analysis of blogs by combining lexical knowledge with text
  classification.
\newblock In {\em Proceedings of the 15th ACM SIGKDD international conference
  on Knowledge discovery and data mining}, pages 1275--1284. ACM, 2009.

\bibitem{montani2018tuwienkbs}
Joaqu{\i}n~Padilla Montani.
\newblock Tuwienkbs at germeval 2018: German abusive tweet detection.
\newblock {\em Austrian Academy of Sciences, Vienna September 21, 2018}, 2018.

\bibitem{poursabzi2017manipulating}
Forough Poursabzi-Sangdeh, Daniel~G Goldstein, Jake~M Hofman, Jennifer~Wortman
  Vaughan, and Hanna Wallach.
\newblock Manipulating and measuring model interpretability.
\newblock In {\em NIPS 2017 Symposium on Interpretable Machine Learning}, 2017.

\bibitem{preece2018asking}
Alun Preece.
\newblock Asking ‘why’in ai: Explainability of intelligent
  systems--perspectives and challenges.
\newblock {\em Intelligent Systems in Accounting, Finance and Management},
  25(2):63--72, 2018.

\bibitem{ribeiro2016should}
Marco~Tulio Ribeiro, Sameer Singh, and Carlos Guestrin.
\newblock Why should i trust you?: Explaining the predictions of any
  classifier.
\newblock In {\em Proceedings of the 22nd ACM SIGKDD international conference
  on knowledge discovery and data mining}, pages 1135--1144. ACM, 2016.

\bibitem{richardson2018survey}
Ariella Richardson and Avi Rosenfeld.
\newblock A survey of interpretability and explainability in human-agent
  systems.
\newblock In {\em XAI Workshop on Explainable Artificial Intelligence}, pages
  137--143, 2018.

\bibitem{rother2018ulmfit}
Kristian Rother, Marker Allee, and Achim Rettberg.
\newblock Ulmfit at germeval-2018: A deep neural language model for the
  classification of hate speech in german tweets.
\newblock {\em Austrian Academy of Sciences, Vienna September 21, 2018}, 2018.

\bibitem{ruping2006learning}
S~R{\"u}ping.
\newblock Learning interpretable models, 2006.

\bibitem{selbst2017meaningful}
Andrew~D Selbst and Julia Powles.
\newblock Meaningful information and the right to explanation.
\newblock {\em International Data Privacy Law}, 7(4):233--242, 2017.

\bibitem{smailovic2013predictive}
Jasmina Smailovi{\'c}, Miha Gr{\v{c}}ar, Nada Lavra{\v{c}}, and Martin
  {\v{Z}}nidar{\v{s}}i{\v{c}}.
\newblock Predictive sentiment analysis of tweets: A stock market application.
\newblock In {\em Human-computer interaction and knowledge discovery in
  complex, unstructured, Big Data}, pages 77--88. Springer, 2013.

\bibitem{van2018contrastive}
J~van~der Waa, J~van Diggelen, K~van~den Bosch, and M~Neerincx.
\newblock Contrastive explanations for reinforcement learning in terms of
  expected consequences.
\newblock {\em XAI 2018}, page 165.

\bibitem{ventocilla2018taxonomy}
Elio Ventocilla, Tove Helldin, Maria Riveiro, Juhee Bae, Veselka Boeva,
  G{\"o}ran Falkmann, and Niklas Lavesson.
\newblock Towards a taxonomy for interpretable and interactive machine
  learning.
\newblock In {\em XAI Workshop on Explainable Artificial Intelligence}, pages
  151--157, 2018.

\bibitem{vorm2018assessing}
Eric~S Vorm.
\newblock Assessing demand for transparency in intelligent systems using
  machine learning.
\newblock In {\em 2018 Innovations in Intelligent Systems and Applications
  (INISTA)}, pages 1--7. IEEE, 2018.

\bibitem{wachter2017right}
Sandra Wachter, Brent Mittelstadt, and Luciano Floridi.
\newblock Why a right to explanation of automated decision-making does not
  exist in the general data protection regulation.
\newblock {\em International Data Privacy Law}, 7(2):76--99, 2017.

\bibitem{watanabe2018hate}
Hajime Watanabe, Mondher Bouazizi, and Tomoaki Ohtsuki.
\newblock Hate speech on twitter: A pragmatic approach to collect hateful and
  offensive expressions and perform hate speech detection.
\newblock {\em IEEE Access}, 6:13825--13835, 2018.

\bibitem{weihs2003combining}
Claus Weihs and UM~Sondhauss.
\newblock Combining mental fit and data fit for classification rule selection.
\newblock In {\em Exploratory Data Analysis in Empirical Research}, pages
  188--203. Springer, 2003.

\bibitem{xiang2012detecting}
Guang Xiang, Bin Fan, Ling Wang, Jason Hong, and Carolyn Rose.
\newblock Detecting offensive tweets via topical feature discovery over a large
  scale twitter corpus.
\newblock In {\em Proceedings of the 21st ACM international conference on
  Information and knowledge management}, pages 1980--1984. ACM, 2012.

\end{thebibliography}
